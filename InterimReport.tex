%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

\documentclass[11pt,a4paper]{report}

\usepackage{amsmath,amssymb,dot2texi,tikz,enumitem,hyperref,soul}
\usetikzlibrary{shapes,arrows}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\usepackage[T1]{fontenc}
\usepackage[sc]{mathpazo}
\usepackage{fullpage}

\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}


\begin{document}

\begin{titlepage}

\begin{center}

% Upper part of the page
\includegraphics[width=0.50\textwidth]{imperial_crest_colour.jpg}\\[1cm]

\textsc{\LARGE Imperial College London}\\[1.5cm]

\textsc{\Large Interim Report}\\[0.5cm]


% Title
\HRule \\[0.4cm]
{ \huge \bfseries Pony - A Language for Concurrent Computation}\\[0.4cm]

\HRule \\[1.5cm]

% Author and supervisor
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
Michael \textsc{Thorpe}\\
\href{mailto:mt2309@ic.ac.uk}{mt2309@ic.ac.uk}
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
Professor Sophia \textsc{Drossopoulou}
\end{flushright}
\end{minipage}

\vfill

% Bottom of the page
{\large \today}

\end{center}

\end{titlepage}

\setcounter{tocdepth}{2}
\tableofcontents

\newpage
\chapter{Introduction}

With the number of processors available to the programmer increasing every year\cite{freelunch}, there is a growing need for easier and safer parallelism.
In the last year Intel started shipping a 60-core processor, designed for use in HPC\footnote{High Performance Computing}\cite{intel-phi}, which shows a clear need for parallel programming.
There are many problems relating to concurrent programming, with errors being difficult to debug and the code being difficult to maintain, due to the non-determinism present in most concurrent systems.
Problems range from deadlock, where two processes are stuck waiting for each other to finish, to data races, where two processes attempt to read and modify the same data at the same time, causing unpredictable results.
There are other, more human, problems involved in concurrency, as the thought processes required for developers to reason about concurrent programs are different from those for sequential programming.

There are many different solutions to these problems, across a wide range of research areas.
Some approaches, such as locking and semaphores\cite{dijkstra-semaphore} leave the protection of data entirely up to the developer, whose responsibility it is to explicitly manage the concurrency.
Other approaches attempt to leverage existing research into other areas such as utilising types or other forms of static analysis.

However, many of these approaches are either very complicated, prone to errors or suffer from poor performance.
We feel that there is an opportunity for a new language to be created, which will to be high performance and is safe and simple for developers to use.
\\
\\
\begin{itemize}
\item Chapter \ref{chapter:background} describes the relevant previous work in the field of language design for concurrency.
	We explore various methods of managing concurrency, such as the actor-model (section \ref{sec:actor}), ownership types (section \ref{sec:ownership}), regions (section \ref{sec:regions}) and the application of static analysis to locks (section \ref{sec:cyclone}).
\item Chapter \ref{chapter:pony} describes the approaches we have already decided to take in the project and what research has been completed so far.
\item Chapter \ref{chapter:project} details the current plan for the project, along with milestones, potential fallback positions and possible extensions to the project.
	It also states what work we have already completed on the project, along with the challenges we expect to encounter.
\item Chapter \ref{chapter:evaluation} explains how we plan on evaluating the project, we discuss both human and technical evaluations with best case scenarios as well as more realistic expectations.
\end{itemize}

\newpage
\chapter{Background}
\label{chapter:background}

\section{Concurrency and The Actor-Model}
\label{sec:actor}

Actors can be used to model large numbers of different concurrent processes in a logical and realistic manner, in which actors are a primitive in concurrency.
In fact the actor-model can be seen as a continuation of OO message-passing, where objects exist on different threads.
Actors have a mailbox and can send and receive messages, and can react to those messages in a variety of different ways.
The main idea behind the actor-model is that there is no global state, and instead each actor has its own local state and can only affect the state of other actors by sending them messages.

In his thesis, Agha\cite{agha1985} stated that actors can:
\begin{enumerate}[noitemsep]
	\item Send a finite number of asynchronous, buffered messages to other actors, with guaranteed delivery but no ordering guarantees.
	\item Select the behaviour to be executed on receipt of the next message.
	\item Create a finite number of new actors.
\end{enumerate}

\subsection{History}

Actors were first introduced in 1973\cite{hewitt1973} and were inspired by physics and by the real world\cite{hewitt2006} (compared to other models for concurrency, which were based on mathematical models such as set theory\cite{Milner:1993:EIT:151233.151240}).
Several languages, such as Simula (1967) and Smalltalk (1971-72), had some of the first message passing semantics, but the message passing was not designed for actors, but rather as part of their object-orientation, with the messages being sent synchronously, rather than asynchronously.

Actors were formally defined in 1973-1977, though Greif's operational semantics for actors\cite{grief1975} and Baker and Hewitt's Laws for Actors in 1977\cite{hewitt1977}.
However the actor-model did not, and indeed has not, gained much popularity, with Mackay\cite{mackay97} claiming that actors did not catch on because the conceptual model did not map very easily onto an efficient implementation, which developers at the time could use.

\subsection{State of the Art}

There are two popular languages involved in the active development of actors - Erlang and Scala (a JVM\footnote{Java Virtual Machine}-based language), as well as several others (such as SALSA, AmbientTalk, F\#, C++, D and Rust).
Erlang is dynamically typed, runs on its own virtual machine with its own eco-system, whereas Scala runs on top of the JVM with the ecosystem and high level support that it provides.

Scala and Erlang both have their own implementation of actors, the semantics of both being more or less the same.
However there are some key differences.
For example in Erlang, multiple processes in the same VM\footnote{Virtual Machine} share nothing, data is shared by sending a deep copy of the data (or via .
In Scala this is not possible, since you can easily send a mutable reference to another actor - which can lead to race conditions\cite{akka-mutable}.
Scala is a type-safe language, with code being error-checked at compile time for many different problems (such as adding a Boolean to an Int), whereas Erlang has only limited type-safety.

Actors can communicate locally (i.e. running on the same machine) or via a network, typically using a protocol over TCP/IP.

\hl{Pony attempts to take the best parts of these two approaches, with some additional features, such as the prevention of data races without the need for deep copying.}

\subsection{Process Calculi}

Process calculi are formal models of concurrent systems.
The first process calculus was CSP (Communicating Sequential Processes), developed by Hoare in 1978\cite{hoare1978}.
Unlike later process calculi, CSP was designed as a programming language rather than as a mathematical model.
It has some key differences to the actor-model, for example processes in CSP are anonymous whereas in the actor-model processes have identities, and CSP messages are sent synchronously, while in the actor-model they are sent asynchronously.

The $\pi$ calculus\cite{milner1999communicating}, a process calculi, was partly inspired by the actor model, but still has several important differences.
For example communication is named in both.
However in the $\pi$ calculus communication is done over channels, rather than the more direct method used by actors.

The join calculus is another process calculus, developed to help formally model the design of distributed programming languages\cite{fournet1996}.
The join calculus is based on the CHemical Abstract Machine (or CHAM), which can be regarded as the computational model of the $\pi$ calculus.
It tried to avoid some of the problems involved with the $\pi$ calculus\cite{milner1989}, which is based on atomic non-local interactions, making it difficult to implement in a real system.

The reflexive CHemical Abstract Machine (or CHAM)\cite{fournet1996} can be seen as an asynchronous version of the $\pi$ calculus, with several strong restrictions:
\begin{enumerate}[noitemsep]
	\item Scope restriction, reception, and replicated reception are syntactically merged into a single construct, called the definition.
	\item Communication can only occur on defined names.
	\item For every defined name there is exactly one replicated reception.
\end{enumerate}

These restrictions state, in precise language, that the "processes" in the join calculus have definitions (which handle receiving input and other tasks), that they can send messages to named definitions and that for each definition there is exactly one instance.

This calculus can be used to help design, model and implement an actor-based programming language, since it was designed for distributed, asynchronous concurrency\cite{fournet1996}.

\subsection{Concurrency Orientated Programming}
Concurrency Orientated Programming\cite{armstrong2007} (or COP) states that the design of a program should be based on concurrency patterns inherent in the problem.
The main ideas behind COP are:
\begin{itemize}[noitemsep]
\item Systems are built from processes,
\item Processes share nothing by default,
\item Processes interact by sending and receiving asynchronous messages,
\item Processes are isolated.
\end{itemize}

Actors fit perfectly into this paradigm, meeting all of the requirements.
Sharing immutable data between processes is fine since this can be modelled as each process having its own, separate copy of the data.

\subsection{Use Cases for the Actor-Model}

The Actor-Model can be used to help model and reason about many different concurrent systems\cite{hewitt2006}, for example:

\begin{itemize}[noitemsep]
\item Web services with the endpoints as separate actors,
\item Email, with different accounts being different actors,
\item GUI programming, where the view, model and controller are separate actors 	 each passing messages to each other.
\end{itemize}

An advantage of actors is that they allow you to think about concurrency on a more abstract level than approaches such as locking, since conditions like deadlock or race conditions do not occur, since there is no shared state.

\newpage
\section{Actor-Based Languages}

\subsection{Erlang}

In 1986, the Ericsson Computer Science Laboratory began the development of Erlang\cite{armstrong2007} (named after either Agner Krarup Erlang, a Danish mathematician, or ERicsson LANGuage, depending on who you ask).
The Lab was tasked with "providing a better way of programming telephony applications".
In the 1980s telephony requirements were atypical to those of other industries, needing to be very concurrent (handling thousands and thousands of calls at once), but these processes could be very lightweight and each one required very little work.
It was a requirement that the system be very tolerant of faults and allow on-the-fly upgrades without system downtime.
It turns out all of these requirements map very easily and effectively onto the actor-model.

Erlang is now used across industry for so-called "soft real-time" programming in many different areas, including (but not limited to) telecoms (at T-Mobile, Nortel and Motorola), Databases (CouchDB, riak and SimpleDB), Facebook Chat, Trading (Goldman Sachs and Smarkets) and servers for online games (Call of Duty and Battlestar Galactica)\cite{erlang-uses}.

Erlang's syntax, which took inspiration from Prolog, (and in fact the original Erlang interpreter was written in Prolog), is very different from most other programming languages, which may have been a reason for its relatively low popularity.

\begin{figure}[H]
\begin{verbatim}
-module(tut15).

-export([start/0, ping/1, pong/0]).

ping(Pong_PID) ->
    Pong_PID ! {ping, self()},
    receive
        pong ->
            io:format("Ping received pong", [])
    end,
    ping(Pong_PID).

pong() ->
    receive
        finished ->
            io:format("Pong finished", []);
        {ping, Ping_PID} ->
            io:format("Pong received ping", []),
            Ping_PID ! pong,
            pong()
    end.

start() ->
    Pong_PID = spawn(tut15, pong, []),
    spawn(tut15, ping, [Pong_PID]).
    
\end{verbatim}
\caption{Erlang Ping Pong\cite{erlang-ping}}
\label{fig:erlang-ping}
\end{figure}

Figure\ref{fig:erlang-ping} show some example Erlang code - demonstrating some very different syntax and semantics to that which programmers usually expect from languages such as Java or C.
In Erlang, $spawn$ creates a new process, returning the PID of the process, $!$ sends a message to another process and receiving messages is handled by pattern matching.

\subsection{Scala \& Akka}

The programming language Scala, developed at EPFL\footnote{\`{E}cole Polytechnique F\'{e}d\'{e}rale de Lausanne} in Switzerland, which was designed to be the successor to Java, integrating functional alongside object-orientated programming.
It includes a myriad of orthogonal features, including anonymous functions, lazy initialisation, pattern-matching, continuations, type inference and operator overloading.

Scala has significant library support for actors, with the Akka framework.
Originally there were two competing actor implementations, scala.actors and akka.actors, with scala.actors being replaced with akka actors in version 2.10\cite{scala-actor-migration}.
Both frameworks were designed to look like Erlang syntax using operator overloading.
Akka includes a large amount of documentation for using Akka-style actors.
It also includes several different kinds of actors: Actors (standard actor), Typed Actors (a more restrictive actor, with static context) and Remote Actors (which can run on remote machines).
The distribution provides a complete system for using actors in production environments.

\begin{figure}[H]
\begin{verbatim}
import akka.actor._

class Ping extends Actor {
  val a = ActorSystem("Ping").actorOf(Props[Pong],name="ping")
  def receive = {
    case "ping" =>
      println("ping")
      a ! "pong"
  }
}

class Pong extends Actor {
  def receive = {
    case "pong" =>
      println("pong")
      sender ! "ping"
  }
}

object main extends App {

  val a = ActorSystem("Ping").actorOf(Props[Ping],name="pong")

  a ! "ping"

}
\end{verbatim}
\caption{Scala Ping Pong}
\label{fig:scala-ping-pong}
\end{figure}

Figure \ref{fig:scala-ping-pong} shows an example usage of Akka actors, where two actors reply to each other in an infinite loop.
This style of code is more familiar to developers who have experience in languages such as Java.

\subsection{AmbientTalk}
\label{sec:ambienttalk}

AmbientTalk\cite{ambienttalk-failure} is an experimental language, developed at Vrije Universiteit Brussel, designed to write distributed software across low quality wireless networks.
Its design was strongly influenced by SmallTalk (block closures, keyworded messages), with its concurrency model based on the actor-model which supports futures and event-loops.
Its primary function is to experiment with new language features and abstractions to help design software which needs to run on highly volatile networks.
The system will automatically buffer messages that the receiver fails to receive which means the programmer can abstract out temporary network failures.
AmbientTalk runs on top of the JVM, meaning that Java libraries can be used easily.
The model is designed such that JVM threads cannot interfere with the concurrency inherent in Ambient Talk\cite{ambienttalk-interfere}

\begin{figure}[H]
\begin{verbatim}
>def calculator := actor: {
  def add(x,y,customer) {
    customer<-result(x+y)
  };
};
>><far ref:behaviour of <actormirror:14115383>>

>calculator<-add(1,2,object: {
  def result(sum) {
    system.println("sum = " + sum);
  };
});
>>nil

>calculator<-add(1,2,object: {
  def result(sum) {
    system.println("sum = " + sum);
  };
});
>>nil
\end{verbatim}
\caption{AmbientTalk Calculator\cite{ambienttalk-example}}
\label{fig:ambienttalk-calc}
\end{figure}

In figure \ref{fig:ambienttalk-calc}, the REPL\footnote{Read Evaluate Print Loop} creates a new actor, sends it a message with a code block as the last parameter that allows it to print out the result.

\subsection{SALSA}

The SALSA programming language (Simple Actor Language System and Architecture) is an actor-based language, which is compiled to Java source, then Java byte code, running on top of the JVM.
In SALSA, a lot of emphasis is placed on continuations:
\begin{itemize}[noitemsep]
	\item Token-passing continuations - sending a message to a customer after processing a message (the customer is often the actor who sent the original message)
	\item Join continuations - where a customer receives an array of tokens from multiple actors, waiting until all actors have finished processing before continuing.
	\item First-class continuations - the delegation of computing to a third party\cite{salsa-continuations}
\end{itemize}

\begin{figure}[H]
\begin{verbatim}
/*
   This behavior simply sends two print(...) messages to the
   standardOutput actor.
*/
behavior HelloWorld {
   /*
      The act(...) message handler is invoked by stand-alone
      theaters automatically and is used to bootstrap salsa
      programs.
   */
   void act( String[] argv ) {
      standardOutput<-print( "Hello" ) @
      standardOutput<-print( "World!" );
   }
   /*
      Notice that the above code is different from
         standardOutput<-print( "Hello" );
         standardOutput<-print( "World!" );
      the code above uses a continuation to insure that the
      world message is sent after the hello message
      completes processing.
   */
}
\end{verbatim}
\caption{SALSA Hello, World\cite{salsa-example}}
\label{fig:salsa-helloworld}
\end{figure}

In figure \ref{fig:salsa-helloworld} we see how actors are utilised in SALSA: messages can have an enforced partial order, which is against the principle of the actor model (where messages can arrive in any order).
SALSA solves this by grouping the messages into a single message before sending them to the other actor.
This allows a programmer to specify partial orderings in the messages, which is very useful for tasks relating to I/O.

\newpage
\section{Type-based Solutions to Safe Concurrency}

\subsection{Ownership Types}
\label{sec:ownership}

Ownership types, first described by Clarke\cite{clarke1998}, are an attempt to prevent aliasing-based failures of encapsulation.

\begin{figure}[H]
\begin{verbatim}
    class MyClass {
        private List list;

        List getList() {
            return this.list;
        }
    }
\end{verbatim}
\caption{Encapsulation Violation}
\label{fig:encapsulation}
\end{figure}

In figure \ref{fig:encapsulation}, encapsulation has been violated, the receiver is free to modify $list$ in whatever way it likes.

Ownership types can be seen as a form of dependent typing\cite{augustsson1999cayenne}(where types depend on values), enforcing several properties about an object:

\begin{itemize}[noitemsep]
\item Every object has an owner, which is another object.
\item Ownership is acyclic (there are no cycles in an ownership graph)
\end{itemize}
These two properties organise the heap into a tree-structure

\begin{figure}[H]
\begin{center}
\begin{dot2tex}[dot,options=-tmath,scale=0.5]
digraph Immutability {
	1 [shape=ellipse,label="1:Object"];
	2 [shape=ellipse,label="2:A<1>"];
	3 [shape=ellipse,label="3:B<1>"];
	4 [shape=ellipse,label="4:C<2>"];
	5 [shape=ellipse,label="5:B<2>"];
	6 [shape=ellipse,label="6:A<3>"];
	7 [shape=ellipse,label="7:C<2>"];

	1 -> 3 -> 6;
	3 -> 2 -> 5 -> 7;
	4 -> 2;
	4 -> 5 -> 6;
}
\end{dot2tex}
\end{center}
\caption{Ownership Hierarchy}
\label{fig:ownership-hierachy}
\end{figure}

Figure \ref{fig:ownership-hierachy} shows an ownership hierarchy, where each node is an object, their contents describing their address, class and owner (e.g. 5:$B<2>$ is an object at address 5, of class C owned by the object at address 2) and each edge is a field reference.

We can represent ownership as sets:
$\/2.owned=\{4,5\}$, $2.owned^{*}=\{4,5,7\}$ and $5.owned=\{6,7\}$\footnote{where $owned^{*}$ is everything in the tree below the object}.
By general intuition, if $x$ and $y$ are not aliases, and neither owns the other, then $x.owned^{*} \cap x.owned^{*} = \emptyset$.
An object, $a'$, is said to be dominated by another object, $a,$ at a point in execution if all paths from the root object to $a'$ go through $a$.

Ownership types confer several advantages: safer parallelism and reasoning.
Safer parallelism\cite{boyapati2002ownership} can be achieved by ensuring that if a thread requires a lock on an object, it must first hold a lock on the root owner of the object.

If $x.y$ and $x.z$ are not in each others ownership sets, then $x.y.method$ will maintain
all properties about $x.z$ (and vice versa).

There are some disadvantages to this approach, for example transferring ownership of an object from one object to another is not easy in a static type system\cite{clarke1998}.
There is also a complexity overhead of annotating code with the specific owner of the code.

\subsection{Regions and X10}
\label{sec:regions}

The Partitioned Global Address Space model\cite{pgas} is another parallel programming model, which assumes that the global address space is partitioned, with a portion of it assigned to each thread.
This approach has some additional advantages, since each processor can exploit locality of reference.
An object can be in either local memory (and therefore local to a thread) or else in the global address space (in the address space related assigned to the thread in question).

X10\cite{x10} is a programming language developed at IBM, designed for very high powered computation across clustered environments, which uses the PGAS model.
The language introduces higher-level concurrency constructs, such as atomic sections in place of locks, clocks instead of barriers and asynchronous operations in lieu of threads.
A computation in X10 is divided amongst a set of different places, where each place holds one or more activities that operate on the data stored in different storage classes.
The different classes of storage are: activity-local, place-local (can be accessed by all activities executing in the same place), partitioned-global (in the global address space, accessible by activities in all places) and as values (stateless, immutable data)\cite{x10-places}.
Places are used for managing concurrency by only permitting mutable data to be accessed from an activity in the same place as the data\cite{charles2005x10}.

\subsection{Cyclone}
\label{sec:cyclone}

Cyclone\cite{grossman2005cyclone} was designed to be a safer-version of C, attempting to avoid some of the more common vulnerabilities in C programs such as buffer overflows.
This is achieved by changing some of the semantics of C (limited pointer arithmetic, only safe casts permitted and forcing pointer-returning functions to return) and by extending the language (garbage collection, polymorphism, exceptions and never-$NULL$ pointers).
Concurrency in Cyclone is handled with a secondary type system, focussed around locks and mutual exclusion.
Cyclone's type-system assigns each data object a lock, which a thread must hold access to when the object is accessed or mutated.
Static analysis checks that a thread only access data if it holds the appropriate lock.

\newpage
\section{Language Features}

In the actor-model, serialisation is necessary in order to send objects - with object cloning being a simpler problem to initially solve.
 
\subsection{Current Solutions to Object Cloning}

In Java, object cloning is achieved by implementing the $Cloneable$ interface\cite{java-cloneable}. This gives the class a $clone()$ method, which if no direct implementation is given, will do a "shallow copy" by copying all of the fields in the original object to the new object.
If this method is overridden, the class provide its own mechanisms after calling $super.clone()$ such as duplicating some fields, or creating a new unique-identifier.

In C++, classes can define a copy constructor or else the compiler will automatically generate one\cite{ansi:03:c++}. This specifies which fields to copy, and in the case of the compiler generated version, will do a shallow copy of all of the fields.

\subsection{Current Solutions to Serialisation}

In Java, serialisation is achieved automatically by implementing the $java.io.Serializable$ \cite{java-serializable} interface, which allows the saving or sending of an object and the fields it references.
C and C++ do not have such easily utilisable methods in their standard libraries.

In the .net framework, a class can become serialisable by adding the $Serializable$\cite{net-serializable} attribute to the class, if (in the future) new members are added to the class, they can be tagged with the $OptionalField$ attribute\cite{net-optional}, allowing older versions of the object in question to be deserialized without problem.

\subsection{Type Inference}

Type inference\cite{damas-milner} combines the safety of static types\cite{palsberg199419} (by doing all of the type checks associated with static typing), with the convenience of dynamic typing\cite{Abadi:1991:DTS:103135.103138}(by reducing the amount of typing required).
There are two "types" of type inference, global and local.

Global type inference was first introduced with Hindley-Milner\cite{hindley-milner}, and can infer the types of functions in polynomial (or linear) time.
The huge advantage of global inference is that it checks the program as a whole and can infer cross-function correctness.
However, Hindley-Milner style inference precludes the introduction of subtypes\cite{Mitchell:1984:CTI:800017.800529} (and therefore prevents us from adding several useful programming tools, such as interfaces or traits, to the language).
Languages with support for global type inference include Haskell and ML (including languages such as F\# and OCaml).

Local type inference, introduced by Pierce and Turner\cite{pierce1997local}, can infer missing types only from the types of adjacent syntax nodes\cite{hosoya1999good}, the purpose of which is to "eliminate especially those type annotations that are both common and silly"\cite{pierce2000local}.
It is much easier to implement a local type inference scheme, as the number of constraints that need to be examined are limited to a very few nearby nodes.
We should also consider that local type inference forces us to include top-level types (such as input and output parameters) when writing code, which serves as a useful form of documentation\cite{pierce2000local}.
Languages with support for local type inference include C++11, Scala, C\# and Java.

\newpage
\section{Architecture}

When designing the compiler, it will be necessary to decide what processor architecture to compile to, taking into account complexity, performance, debugging and the tools available.

\subsection{x86}

x86, and its 64-bit counter-part x86\textunderscore64\cite{intel-x86}, is the primary instruction set used on desktop machines.
It has a wider array of development tools, documentation and support.
Almost all the x86\textunderscore64 processors available on the market are multi-core, meaning that an actor-model language would see performance benefits from concurrent execution, allowing us to more easily demonstrate the performance benefits of the language.
x86, however, is difficult to write a faster compiler for, because of the large number of instructions and complexity of the architecture (since it is a CISC architecture).

\subsection{ARM}

The ARM ISA\footnote{Instruction Set Architecture} is the most popular architecture in terms of sheer numbers in use today, with 6.1 billion ARM chips being shipped in 2010\cite{theregister2011}.
The architecture is RISC\footnote{Reduced instruction set computing}, i.e. a reduced instruction set.
This means that writing a compiler targeting the architecture is much simpler, as there are fewer instructions and the complexity of the code generator is reduced.
However, almost all of the 6 billion chips are low-powered and can be found in devices such as set-top boxes (and the rest are in slightly higher powered devices such as tablets and mobile phones), which are not suited for high-performance computing.
It could be beneficial to target ARM if we were going to implement actors in a similar fashion to AmbientTalk (see section \ref{sec:ambienttalk}), for handling distributed actors over poor connections.

\subsection{JVM or CLR}

Targeting the JVM or CLR\footnote{Common Language Runtime - aka the .net framework} would be very convenient, as it would be mean we would not need to worry about manually managing memory or simple optimisations. 
The VM would be able to optimise them out at run time, for only a small performance hit.
Unfortunately, this is not a route we wish to take on this project, as we do not want the overhead of running on top of a VM, since it means the actor garbage collector already developed would not work.

\subsection{C}

Translating Pony code into C, and then compiling with GCC/Clang would be very beneficial for a large number of reasons:
\begin{itemize}[noitemsep]
	\item Fast - allowing a C compiler with many years of research to optimise our code would significantly reduce the complexity of the compiler.
	\item Debugging support - the C compiler would be able to emit warnings and errors that the Pony compiler might have missed.
	\item Cross-platform - as long as the C compiler could target the architecture in question, we would be able to compile Pony to that platform.
\end{itemize}

However, the debugging support listed as an advantage may not to be very helpful, since this is likely to confuse developers if the "Pony" compiler suddenly starts complaining about error messages in the C code produced.

\subsection{LLVM}

LLVM\footnote{Low Level Virtual Machine} is a compiler infrastructure project developed at the University of Illinois as a way to help investigate dynamic compilation techniques\cite{Lattner:MSThesis02}.
LLVM consists of various front-ends, which translate different programming languages into LLVM IR\footnote{Intermediate Representation}, along with optimisers and code generators.
LLVM has many advantages over other, more traditional compilation options:
\begin{itemize}[noitemsep]
	\item Performance - LLVM can perform many standard optimisations, as well as lower level register allocation optimisations
	\item Cross-platform, LLVM can target almost every major ISA in use today\cite{llvm-svn}, with no front-end changes required (as well as compiling "up" to higher-level languages such as Javascript.)
	\item Debugging support - LLVM intrinsics allow the use of tools such as GDB/LLDB\footnote{GNU Debugger/LLVM Debugger} to step through a currently running program, with source code representations of the software shown.
	\item Ease of use - LLVM has extensive documentation and removes much of the work needed to write a compiler, reducing it to lexing, parsing, type-checking and minimal code generation.
	\item C interoperability - LLVM easily allows you to include/call C libraries at link time.
	\item IR emission - LLVM allows us to simply call library functions, which builds up the the IR before writing to disk, rather than having to emit hand crafted (and potentially buggy) assembler\cite{ibm-llvm}.
\end{itemize}

\newpage
\chapter{Pony}
\label{chapter:pony}

This project will focus on designing and creating a new programming language called Pony, which will introduce a relatively novel kind of type system, determining mutability, immutability and uniqueness.
This language will treat actors as first class members and will have several relatively unexplored features for a programming language, including no inheritance (but with traits to allow code reuse), a feature called partial objects and with referential immutability expressed in the type system.
In order to garbage collect actors, Pony will break the "no ordering guarantee" aspect of the actor-model (as described in Agha's thesis\cite{agha1985}).

Pony will be a:
\begin{itemize}[noitemsep]
	\item high level
	\item imperative
	\item object oriented
	\item functional
	\item single-dispatch
	\item statically-typed
	\item actor-model programming language.
\end{itemize}
It will be a "pure" object-orientated language in that every value is an object.
It will be a functional language in that every function is a value, with Algebraic Datatypes as first class members of the language.
It will be strongly typed, with local type-inference\footnote{However given that we will be aiming for a closed-world compilation, we could do some level of global inference}.

There will be no class inheritance.
To avoid code duplication, Pony will use Scala-style traits/Ruby-style mixins.
This means that types are composed\footnote{by mixing in multiple traits} rather than having a type hierarchy.
Pony will have, built into its type-like system, a system for handling reference modes, which has a sub typing relationship.

The syntax of Pony takes inspiration from languages such as Scala and Lua\cite{lua}, with C style bracing and semi-colons.
The grammar is still not fixed, with discussions on the language, grammar and semantics still on-going.

In contrast to Erlang and Scala, Pony will run natively, with only a small runtime for the actor-framework and garbage collection, with the use of the LLVM backend allowing for C library interoperability.

\begin{figure}[H]
\begin{verbatim}
  actor Runnable {
    function main(args:Array[String]) {
      for arg in args {
      	io.println(args);
      }
    }
  }
\end{verbatim}
\caption{Example Pony program}
\label{fig:simple}
\end{figure}

In figure \ref{fig:simple} a sample Pony program which simply prints its arguments, one per line (I/O is handled via the IO actor).
In this example several properties of Pony become visible:
\begin{itemize}[noitemsep]
	\item Actors are the base objects for building a system.
	\item A for-comprehension - similar to a $for$ loop in Java, C\# or C, but with
		a more expressive syntax.
	\item Sending an actor a message is no different to calling a function (the io function call is, in fact, sending an actor a message).
\end{itemize}

\section{Partial Objects}

Pony unifies the concepts of cloning and serialisation, which are needed for sending messages to actors, under a single feature called Partial Objects
They have other uses, such as stringifying an object.
They are not created by the user, but automatically generated by the compiler.
For the rest of this paper, I will express a partial object of type $T$ as $\backslash T$

\begin{figure}[H]
$T = (fieldId \to type) \times (function \to signature)\\$
$dom(T\downarrow_{1}) = \{ f_{1} \dots f_{n} \} \Rightarrow\\$
$\> \exists \backslash T.dom(\backslash T\downarrow_{1}) = \{f_{1}^{'}\dots f_{n}^{'}\wedge
\forall_{i\in 1\dots n}.\backslash T\downarrow_{1} \in \{T\downarrow_{f_{i}},
\backslash(T\downarrow_{1}(f_{i}), undefined\}$
\caption{Formal Representation of Partial Objects}
\end{figure}

That is, for each field in $T$, the field can be $T_{n} \wedge \backslash T_{n}$ (so a partial $T_{n}$) $\wedge undefined$ (the field doesn't exist).
The potential of this is not immediately obvious, but the advantages for the developer will become apparent later on in this report.
This simple concept can be shown to easily solve problems such as cloning, serialisation and stringability.
For now we will get a partial object by calling $reflect(pattern)$ where $pattern$ is optional and specifies what fields are to be returned on $this$ (the default being all public fields), which returns a partial object of type $this.type$.
Reflect returns a mirror\cite{mirror-paper} of the object in question, allowing for meta-properties in the original object to be maintained, such as encapsulation and capabilities.

\begin{figure}[H]
\begin{verbatim}
    function toString()->(r:String) {
        r = "";
        var mirror = reflect();
        for name,value in mirror.fields() {
            match value {
                case substring as v:Stringable {
                    r = r + name ":\t" + value.toString() +"\n";
                }
                case {}
            }
        }
    }
\end{verbatim}
\caption{Example usage of partial objects}
\label{fig:partialobj}
\end{figure}

In the code above we can see some more of the syntax and ideas of Pony, as well as the power of partial objects.

\section{Modal References}
\label{sec:immutability}

Modal references - mutability enforced by the type system\cite{tschantz2005javari}\cite{zibin2007object}\cite{zibin2010ownership} - can be used to enforce safe concurrency.
If the language prevents the user from sharing mutable data, the language prevents race conditions.
A reference can possess one of four qualifiers\cite{microsoft2012}

\begin{itemize}
	\item Mutable - the "standard" reference to an object - mutation of the object is allowed.
		The object can refer to any other kind of qualifier with no restrictions.
	\item Read-only - a read-only reference to an object, allowing for no mutation.
		There is an additional restriction on read-only values, in that traversing the heap through a read-only reference will only ever produce non-mutable references
	\item Immutable - a read-only object with a further restriction in that no other references to that object are able to mutate it.
	\item Unique\cite{haller2010capabilities} - an external reference to a cluster of externally unique references, such that there is only one "entrance" reference to the object graph.
		There is an exception to this, in that if the object graph contains immutable references, the immutable references can be safely referred to.
\end{itemize}

In order to maintain safe concurrency, each qualifier carries with it a unique set of capabilities (what you can do with the reference in question).
Capabilities are:
\begin{itemize}[noitemsep]
	\item immutable/readonly - can read from the reference
	\item write/unique - mutable/unique - can write to the reference
	\item unique - can send the reference to another actor (which consumes the reference)
	\item immutable - can share the reference with multiple actors
\end{itemize}

The "mode" of a reference (which can be seen as comparable to a file reading mode - read, write etc) dictates what can be done.

\begin{figure}[H]
\begin{center}
\begin{dot2tex}[dot,options=-tmath,scale=0.5]
digraph Immutability {
  rankdir=BT;
  mutable	-> readonly;
  immutable -> readonly;
  unique	-> immutable;
  unique	-> mutable;
}
\end{dot2tex}
\caption{Mode Hierarchy}
\label{fig:mode-hierarchy}
\end{center}
\end{figure}

Objects can be upcast the hierarchy (i.e. $unique \to mutable$) without problem.
However downcasting is not permitted, as this violates capability constraints (downcasting from mutable to unique means it would be possible to send it to another actor).

Pony will provide a simple syntax for describing these modes and will infer the mode of references whenever possible.
For now the syntax for modes is as follows: readonly - no notation (being the default),  mutable - \textasciitilde (think $\rightsquigarrow$ for heap mutation), immutable - ! and unique - @.
This is in construct to the Microsoft paper\cite{microsoft2012}, which required  long and ugly code annotations.
A user can be more verbose and state the mode for clarity, as well as to specify that the mode of a method parameter is the same as another parameter.
For example the add method of a collection of immutable objects needs to verify that the object being added is also immutable (but the method itself doesn't need to know about the mode).

Conversions to and from unique should be possible, since uniqueness does not fit into the hierarchy in the purest sense.
Since unique references are only accessible from a single thread, they can become mutable.
They can also be converted to immutable, since a single thread holds a reference the decision to treat the object cluster as immutable is localised.

\begin{figure}[H]
\begin{verbatim}
    var x@ = new Array(....);
    // ...
    x(0) = ...; // x converted to mutable
\end{verbatim}
\caption{Conversion to mutable}
\end{figure}

\begin{figure}[H]
\begin{verbatim}
    var x@ = new Array(...);
    var y! = x; // x implicitly converted to immutable
    x(0) = ...; // x is now out of scope, so compilation error
\end{verbatim}
\caption{Conversion to immutable}
\end{figure}

We can also recover uniqueness from a conversion to mutable/immutable, inside the body of a function, as the conversion does not mean we permanently lose the information.

\begin{figure}[H]
\begin{verbatim}
    function! double(x:Object@)->(y:Object@) {
        // make x mutable
        x.field = 2;
        // y can be safely converted to unique
        // since there is only one reference left at
        // the function exit point - y
        y = x;
    }
\end{verbatim}
\caption{Conversion to and from unique}
\end{figure}

This ability is very useful, since it means we can easily parallelise destructive operations on collections of unique objects, as each process can violate the uniqueness constraint, do the operation and return the unique reference.

\section{Additional Information}

There has been an actor runtime written at Imperial College London, which allows for actors to be garbage collected, new actors to be created and scheduled, and messages to be sent between actors.
This runtime allows us to focus on the programming language side of the project without having to worry about the implementation of the actor-model.

Pony will feature traits\cite{traits} (or mixins\cite{esterbrook2001using}), which encourage code re-use, but avoid the problems associated with multiple inheritance\cite{boyland1996type}.
Traits can be considered to be an interface with already-implemented methods.

\newpage
\chapter{Project Plan}
\label{chapter:project}

\section{Investigation}
The first step of the project will be an investigation into the design of programming languages, and I will look at which features could be useful, targeting specific areas where Pony will be used.
It will also look at the style of code that programmers want to write in the language.
An investigation into LLVM and the Intermediate Representation it uses will also be necessary.

\section{Design}
The next step will be to design the full Pony language and decide on an initial, concrete syntax for the language (the operational semantics for the language having already been formalised).
The specification should comprise a grammar in EBNF, along with a description of the semantics of the language.
At this point the specification should be considered flexible and open to considerable change.

\section{Implementation}
The implementation side of the project will consist of several parts once a specification has been formalised.

\begin{enumerate}
	\item Initial test code in Pony that should be possible to compile.
	\item A Pony compiler for a small subset of the language (Pony-) written in a native language (such as C++) with error handling for features included
		Lexing and Parsing of the full language, which means we can use all of the C++ debugging tools available to us to debug the parser, which will need to be hand-rolled (as there will be no parser generator for Pony).
		This also means we can easily port the C++ code to Pony and requires no maintenance once implemented.
		The features we will include in Pony- are:
		\begin{itemize}[noitemsep]
			\item Object oriented features, such as classes, traits and objects.
			\item Minimal type checking, with no inference
			\item No partial objects
			\item Output LLVM IR
		\end{itemize}
	At this point we will not consider modes in the type system at all, as this will make the initial compiler easier (annotations will be supported, if they are not too difficult)
	\item An initial Pony compiler, written in Pony as a reimplementation of the C++ compiler.
		This will serve as a test of the expressiveness of the language and let us determine what may need to be added to the language.
	\item Incremental improvements to the compiler, adding features such as partial objects, mutability inference and optimisations based on mutability (for example, caching immutable values), written in Pony.
    	\item Use the actor framework to do parallel compilation and optimisation.
\end{enumerate}

\section{Challenges}

\subsection{Infrastructure}

In order to explore the more interesting parts of this project, a fully working compiler needs to be constructed.
This is obviously a large undertaking, and errors in the actual compiler could cause errors in the type system, making debugging considerably harder.

The fact that this is a new programming language also means the tools are not very robust and the errors emitted by the compiler will be less clear and less informative\footnote{And sometimes not even correct error messages!} than in a more mature implementation.
There will also only be a limited support network of two or three people at Imperial College London!

\subsection{Technical Challenges}

Problems that might arise directly related to the modal-type system
	\begin{itemize}
		\item How to interoperate with other LLVM code. For example if a developer was using the OpenGL LLVM API, should we consider all return values to be mutable?
			Or should we require users to provide wrappers to the external code, annotating as appropriate.
		\item Allowing casting. Should we allow an implicit conversion from unique $\to$ mutable/immutable.
			Will there be any problems related to this?
		\item Generic mode types - what is the most useful and readable manner of representing generic modes and how should they be treated in the type system.
	\end{itemize}
	
\section{Fallback Positions}
If we find we are running out of time, there are several different paths we could take that would simplify the project, whilst still retaining the original goals.
\begin{itemize}[noitemsep]
\item No bootstrapping.
	If we abandon the idea of writing the compiler in Pony, we will be able to save a lot of repetition of work, as well as having a lot of reference material related to C++ available to us.
	The downside to this is that the amount of Pony code we would write would be much lower and thus bugs in the compiler might not be discovered.
\item Removal of features.
	We could remove some of the features from the language, such as partial objects, which would reduce the amount of work needed for the project.
	The obvious downside to this is that removing features makes the language less desirable and less useable.
\item Use external standard library.
	 Since we have chosen to use LLVM, we can link with external libraries, removing the need for efficient, well tested library code written in Pony.
\end{itemize}

\section{Current Progress}

\begin{itemize}
\item We have a grammar, which has been mostly agreed on, with some discussion still on-going with respect to issues (such as semi-colon line endings).
	The grammar is LL(1), with no ambiguity, represented as an ANTLR grammar. 
\item We have written the first stages of the C++ compiler, with a lexer and parser and a useful level of error-reporting.
	The parser is implemented as a recursive descent parser, with the grammar easily viewable in the parser code.
\item We have written a semantic analyser, checking the types and building a symbol table for a Pony file.
	There is no implementation of modal references and the type checker currently warns that they are not implemented (since the parser can handle them as part of the grammar).
\item We have done work towards a standard library, including operations on primitive types, which includes arrays.
	In the standard library there is also a partial hashmap implementation, as well as a standard linked list.
\end{itemize}

\section{Timetable}

The dates below are approximations of when we hope to achieve each step.

\begin{enumerate}[noitemsep]
	\item Finish initial research and investigation - 3rd December
	\item Initial grammar and semantics - 14th December
	\item C++ Lexer and Parser - 2nd January
	\item Pony- type checking - 18th January
	\item Pony- code generation - 8th February
	\item Initial Pony compiler - 22nd February
	\item Modal References - 8th March
	\item Modal Inference - 22nd March
	\item Partial Objects - 31st May
	\item Further Improvements - 14th June
\end{enumerate}


\newpage
\chapter{Evaluation Plan}
\label{chapter:evaluation}

\section{Test Suite}

A test suite has started to be created, consisting of code that should and should not compile at each stage of the compiler.
The current state of these are in Appendix \ref{app:test}.
These have been useful in evaluating the correctness of the compiler, especially when making small changes to the grammar or semantics of the language.

\section{Best case scenario}

The best case scenario would have a compiler for the full Pony language, with an LLVM backend and a type system capable of correctly proving mutability across a variety of different situations.
There would be a significant standard library, with collections, IO and maths support.
The Pony compiler should be able to compile itself with no errors.

\section{Expectations}

I do not expect to achieve all these goals, since that would be too ambitious for the timescale available for this project.
Instead I will focus on:
\begin{itemize}
\item Correctly implementing the modal side of the type system, as	this is currently an area of active research, with Microsoft having written several million lines of code in a C\# variant\cite{microsoft2012}.
\item An implementation of Partial Objects, in order to demonstrate their usefulness.
	For example implementing stringability via partial objects would be a (relatively) straightforward effort, subject to time available.
\item The bootstrapping process, which should be easily extendable for incremental improvements to the compiler.
\end{itemize}

These will highlight Pony's strengths and will demonstrate them to other people to see what strengths it might have, as well as allowing easy expansion of the compiler and language at a later date.

\section{Code which should compile}

\begin{itemize}

\item Simple code - the example in figure \ref{fig:simple} should compile.
\item Use of partial objects - the example seen in figure \ref{fig:partialobj} should compile with no errors.

\item Should include inferred mutability from the type system

\begin{figure}[H]
\begin{verbatim}
actor Receiver {
  message receive(x@) {
    match x on type {
      case buf:Buffer@ {
        buf.append(4);
      }
    }
  }
}

object main {
  var x = new Receiver;
  var buf = new Buffer(1,2,3);
  x.receive(buf);
  buf.empty();
}
\end{verbatim}
\caption{Example of Inferred Mutability}
\end{figure}

This code should fail to compile, since $buf$ cannot be mutable (as you can only send immutable or unique messages) and cannot be unique, immutable or read-only (as $main$ empties the buffer after it is sent).
At this point the compiler should introduce a warning/error to the developer.

\item Compiler should be able to bootstrap itself (i.e. the Pony compiler should be able to compile the compiler once it is written in Pony).

\item Some form of standard library, including primitive types (int, bool, char, string, array, vector) and file I/O, the essential parts necessary for writing a compiler.
	This means that the compiler can be fully self-hosting, with the only dependency being LLVM.
\end{itemize}

\section{Effectiveness}
\subsection{Ease of Programming}

As part of the evaluation, we would like to see how easy new users of the language find programming in Pony, both for sequential and parallel programming.
A sample of users used to a variety of different languages and programming styles should be used to help evaluate the effectiveness of the language

\subsection{Efficiency}

We must also consider how fast the language is, both in terms of development time, lines of code written and the speed of the compiled code.
A variety of programming tasks, both parallel and sequential should be prepared, with clear specifications and the metric above collected.
These results should be compared to alternative implementations in many different languages, such as C, C++, Scala, Erlang, Haskell, Java, Ruby and Perl.

\bibliographystyle{plain}
\bibliography{InterimReport}

\appendix
\chapter{Test Cases}
\label{app:test}


\end{document}
